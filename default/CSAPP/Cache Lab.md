又是一个新的 Lab 好累，常规，我们先看 write-up 文档。
刚看一会就发现踩坑了，没用 Linux 的 tar 来解压，不过前面几个 lab 好像都是这么过来的……赶紧重新解压一遍。

# Part 2

## Blocking 分块

我们要写一个更快的转置函数，因为原来的函数在访问修改后矩阵的数据时是按照一列进行访问的，所以每一次都会 miss 缓存，我们可以通过分块转置的方法，减少 miss 的次数。
但是由于题目的限制我们只能使用 12 个局部变量，分块的坐标一共就需要 4 个，剩下 8 个该怎么使用呢？
为了提高分块计算的效率，我们还需要尽可能大的分块，已知测试 csim 的参数是 $s=5,E=1,b=5$ 那末 block 的大小就是 32 bits 我们可以塞 8 个 int。设置 `block_size` 为 8。

## 仅仅这样是不够滴

分块并不会让我们的缓存工作起来，每次通过二维数组访问还是会需要用到内存访问，我们把这些变量应用到缓存里的方法就是为他们声明一个变量，刚好我们的 `block_size` 是 8，我们就声明 8 个临时变量，至于 `block_size` 我们就 hardcode 一下吧。
面对 $32\times 32$ 的情况成功把 misses 压到了 300 以下，拿到满分。但很快我们就发现面对 $64\times 64$ 时，直接超时了！怎么会这样？

## Cache Conflict

这是因为出现了大量的缓存映射冲突。我们仔细考虑一下 $64 \times 64$ 的情况，发现如果使用 8 为块大小，那么当行数超过 4 的时候，因为现在的列数是 64 所以 $4 \times 64=256$ 已经到地址上限了，接下来就要取模映射了，那么就会对 A 矩阵的读就会产生冲突，同样在对 B 进行写的时候也会产生冲突，那这是不是意味着我们只能用 $4\times4$ 的块大小进行处理呢？但其实读了这 $4\times 4$ 的区域之后我们缓存中存着 $4\times 8$ 的数据，只用一部分那不就亏了？
唐突打断，疑似硬件有点问题，即便是满分答案在第二个问题也会运行超时，cache lab 堂堂搁置。
