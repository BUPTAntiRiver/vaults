# Chapter 1 Introduction

## What's the Internet?

- **Hosts**: millions of connected computing devices, also known as **end systems**, running **network apps** on it
- Communication links
- **Routers**: forward packets(chunks of data)
- **Protocols**: define format, order of msgs sent and received among network entities, and actions taken on message transmission, receipt

## Network edge

- **Hosts(end systems)**:
  - run application programs
  - e.g. Web, email
- **Client/Server model**:
  - Client host request, receives service from always-on server
  - e.g. Web browser/server; email client/server
- **Peer-peer model**:
  - minimal use of dedicated servers
  - e.g. Skype, BitTorrent

Also has another 2 parts: **access networks** and **links**.

## Network Core

Circuit Switching: **end-end resources reserved for "call"**, divided into pieces, resource piece **idle** if not used.
Packet Swtiching: resources used as needed, each packet uses full link bandwidth, end-end data stream are divided into packets.

## Delay, loss and throughput

**Four sources of delay**:

1. Nodal processing
2. Queueing
3. Transmission delay: R=link bandwidth, L=packet length, T=L/R
4. Propagation delay: d=physical length, s=propagation speed in medium, t=d/s

**Traffic intensity = La/R**, a=average packet arrival rate, when La/R -> 1, queueing delay becomes very large.
Queueing and transmission delay are the 2 main source of delay.
**Throughput**: constrained by the narrowest bandwidth in the transmission path.

# Chapter 2 Application Layer

## Application Architectures

Client-Server, Peer-2-peer, Hybrid of CS and P2P.

### Client-server

- **Server**
  - always-on host
  - permanent IP address
- **Clients**
  - communicate with server
  - maybe intermittenly connected
  - may have dynamic IP addresses
  - do not directly communicate with each other

### P2P

- **no** always-on host
- arbitrary end systems directly communicate (highly scalable but difficult to manage)

## Internet trasport protocols services

### TCP

- **connection-oriented**: setup required between client and server processes
- reliable transport
- flow control
- congestion control

### UDP

Provides nothing but **faster**, can be used in scenes that have more tolerance.

### HTTP

HTTP is an application level protocol(works on port 80) and it uses TCP. It does not remember any states. There are non-persistence connection and persistence connection.
We introduce two types of HTTP messages: **request** and **response**.
**request** has several commands, they are: GET, POST, HEAD, PUT and DELETE.
**response** has status like: 200 OK, 301 Moved Permanently, 400 Bad Request, etc.

### Cookies and Web Cache

Though HTTP does not handle any state information, we use cookies and web cache to do so.
**Cookies** can store information by maintaining state at sender/receiver over multiple transactions, cookies are carried by HTTP messages.

**Web cache** reduces response time for client request. When some resources are requested they are not only send back to the requester but also stored at web cache so that next time when the same content is requested it can be accessed immediately in web cache.

## FTP 文件传输协议

## Email 电子邮件

### SMTP

### POP3

### IMAP

## DNS: Domain Name System

The IP address of a host is too hard to remember, so we have DNS to map between **IP address** and **name**.
DNS is an application-layer protocol, it is implemented in hierarchy of many name **servers**.

### TLD and Authoritative Servers

- Top-level domain (TLD) servers:
  - responsible for com, org, net, edu, etc and all top-level country domains uk, fr, ca, jp
- Authoritative DNS servers:
  - organization's DNS servers

### Local Name Server

Does not strictly belong to hierarchy, when host make DNS query, query is first sent to its local name server. It acts **like a proxy**, forward the query to the hierarchy.

### DNS name resolution

**Iterated query** (the one we use)
Query the local name server, then the local server go into hierarchy and query again and again until it finds the goal.
**Recursive query**
After query the local name server, the local name server query hierarchy server and that server query other server until finds the goal and return.
This method put the burden on the name server, which brings heavy burden.

## P2P applications

### File distribution p2p vs C/S

How much time to distribute file from server to $N$ peers? With file size $F$, server upload bandwidth $u_s$, peer i upload bandwidth $u_i$, peer i download bandwidth $d_i$.
**C/S**
Server sequentially sends $N$ copies of file.
$d_{CS}=\max\{\dfrac{NF}{u_s},\dfrac{F}{\min_i (d_i)}\}$
**P2P**
Server sends 1 copy, totally $NF$ bits of file need to be downloaded (aggregate).
$d_{P2P}=\max\{\dfrac{F}{u_s},\dfrac{F}{\min_i(d_i)},\dfrac{NF}{u_s+\sum u_i}\}$
CS time increases linearly in $N$, P2P increases much slower.

### P2P file distribution: BitTorrent

**Trackers**: tracks peers participating in torrent, users can obtain list of peers from trackers.
**Torrent**: group of peers exchanging chunks of a file.

### P2P case study: Skype

The Skype Clients are connected to a super node which works as "NATs", which prevent outside clients connect to inside clients directly.
If two clients want to setup a connection, they initiates sessions with relay and communicate through NATs using relay.

## Socket Programming

I am gonna just introduce some basic concepts here.
**Socket** works like a door, it is an endpoint where two sessions communicates with each other, only by knowing each other's socket.
Socket is made up of IP+Port+Protocol.

# Chapter 3 Transport Layer

## Transport-layer services

Provide **logical communication** between app processes.
Breaks app messages into smaller **segments** passes to network layer.
Transport layer cares about **processes**, and network layer cares about **hosts**. When network layer delivered data from other hosts arrived, transport layer would tear it into pieces (demultiplex) and send them to according processes.
**TCP**: reliable, in-order delivery, congestion control.
**UDP**: unreliable, unordered.
They both don't have delay guarantees and bandwidth guarantees.

## Multiplexing/demultiplexing

**Multiplexing** at send host, gathering data from multiple sockets, enveloping data with header (later used for demultiplexing).
**Demultiplexing** at receive host, delivering received segments to correct socket.
UDP socket identified by 2 fields: dest IP address and dest port number.
TCP socket identified by 4 fields: source IP address and port number, dest IP address and port number.
Connection less and connection-oriented makes the difference.

## UDP

"no frills", "bare bone", "best effort" service, UDP segments maybe: lost, delivered out of order. So why we bother using UDP?

- No connection establishment (less delay)
- simple: no connection state at sender, receiver
- smaller segment header (only destination)
- no congestion control, so can run faster

### Error detection: Checksum

UDP uses checksum to detect error. It works by treating data as integers and do an addition, then take 2's complement of the sum and you get **checksum**.
If the checksum is different in the sender side and receiver side then there must be some error.

## RDT: reliable data transfer

The principles of rdt has a process of evolution.
**rdt 1.0**: believe the underlying transfer channel is reliable, so it is reliable, sounds pretty unreliable.
**rdt 2.0**: underlying channel may flip bits in a packet, there might be error, so we need **error detection** and let the sender know that so then it will send the data again, here comes the **ACK/NAK** mechanism. ACK means received data OK, while NAK is negative.
**rdt 2.1**: **BUT!!** There is a fatal flaw in rdt 2.0, what if ACK/NAK corrupted? Sender doesn't know what happened, so there comes a new mechanism called **stop and wait** it there is broken ACK/NAK coming sender would resend, and we add a **sequential number** to ACK/NAK in order to handle duplicates.
**rdt 2.2**: we found NAK redundant since we have sequential numbers, we can just use the last ACK to represent NAK (a mismatch). It is also called **NAK-free**.
**rdt 3.0**: the ultimate version, assumes that underlying channel may lose packets (lose ACK/NAK) so we add a timer to listen for ACK/NAK, it the timer runs up, the sender will also re-transmit, the potential duplicate will be handled by sequential number.

Though rdt 3.0 works, but its performance stinks. Because we wait for each packet's ACK, so if the data is small the RTT (round trip time) can be the main source of delay.
We introduce **Pipeline** to increase utilization, which means we send a bunch of packets at the same time.
But this also means we need to modify out rdt protocols to keep up with pipeline.
Two main methods: **Go-back-N** and **Selective repeat**.

### Go-Back-N

Only send ACK for correctly received packet with highest **in-order** seq number.
Has **no receiver buffer**, if received packets unordered, then discard, and send the previous ACK.
Only **one** timer for the whole batch.

### Selective Repeat

Receivers acknowledge each correctly received packets, which means it **has buffer** to maintain the order.
Sender only resend packets which ACK not received, means we have timer for **each packet**.
**Window size issues**: if receiver window size is too big then the selective repeat dilemma may occur.
It means, when packets are send and received but ACK are lost, then the receiver window moved and waits for a new packet 0, but the sender resend the original packet 0 because the ACK is lost, so receiver received wrong packet. This problem occurs because we use cycle of sequence number to denote packet numbers.

## TCP

### Timeout

TCP set timeout value dynamically, if too long slow reaction, if too short premature timeout.
TCP update estimated RTT by iteratively sampling the RTT and add it to current estimated RTT with a coefficient. Also we can add deviation to bring more tolerance. The calculation is below:

$$
\begin{aligned}
\text{EstimatedRTT}&:=(1-\alpha)*\text{EstimatedRTT}+\alpha*\text{SampleRTT}\\
\text{DevRTT}&:=(1-\beta)*\text{DevRTT}+\beta*|\text{SampleRTT}-\text{EstimatedRTT}|\\
\text{TimeoutInterval} &= \text{EstimatedRTT} + 4*\text{DevRTT}
\end{aligned}
$$

### TCP reliable data transfer

- pipeline segments
- cumulative ACK
- TCP uses single re-transmission timer
- re-transmission triggered by:
  - timeout
  - duplicate ACK (fast re-transmission), if sender receives 3 duplicate ACK then re-transmit

### TCP flow control

Senders won't overflow receiver's buffer by transmitting too much, too fast.
The receiver advertises unused buffer space by including `rwnd` value in segment header, then sender limit number of not ACK bytes to send.

### TCP connection management

**Three way handshake** (start a connection):

1. client host sends TCP SYN segment to server, specifies initial seq, no data
2. server host received SYN segment and replies with SYNACK segment
3. client host received SYNACK segment replies with ACK segment which may contain data

**Closing a connection**:

1. client send TCP FIN control segment to server
2. server received FIN and replied with ACK. Closes connection, sends FIN
3. client received FIN and replied with ACK
4. server receives ACK, connection closed

## Congestion control

**end-end congestion control**

- no explicit feedback from network
- congestion inferred from end-system observed packet loss, delay
- approach taken by TCP

**network-assisted congestion control**: routers provide some feedback to the end-systems

## TCP congestion control

TCP should re-transmit as fast as possible but should not congest the network. How to find the rate just below congestion to maximize efficiency?
We decentralize, let each TCP sender set its own rate base on **implicit** feedback:
**ACK** means segment received so the network is not congested, we increase sending rate.
**lost segment**, we assume loss because of network congestion, we decrease sending rate.
But, **how to change** the sending rate?
We introduce a new variable `cwnd` to showcase the number of bytes we send.
When encounter **segment loss**: we reduce `cwnd`, if it is a timeout, we set `cwnd` to 1, if it is duplicate ACK, we cut `cwnd` into a half.
When encounter **ACK received**: when below the threshold, grow in exponential speed, above the threshold, grow in linear speed, threshold is updated when encounter loss, set threshold to half of `cwnd`

# Chapter 4 Network Layer

## 4.1 Introduction

### 4.1.1 Forwarding and Routing

The role of network layer is to **move packets from a sending host to a receiving host**. To do so it has two important functions:

- _Forwarding_: The router moves the received packet from its input link to appropriate output link, which all router-local actions. Processing one **single packet**.
- _Routing_: The router determines the route or path taken by packets as they flow from a sender to a receiver. Refers to network-wide process. Determine where **packets** go.

Every router has a **forwarding table**. A forwarding table can tell which interface should the packet go to by examining the value of a field in its header.
Here comes the question, where does the forwarding table comes from? The answer is by a **centralized** or **decentralized routing algorithm**. In either case, a
router receives routing protocol messages, which are used to configure its forwarding table.

There is actually a third important network-layer function called **connection setup** which is used in specific scenario, and it acts like the handshake in TCP protocol. We will discuss this in Section 4.2.

### 4.1.2 Network Service Models

About the Internet, it uses a _best-effort service_, which is like a euphemism for _no service at all_.

## 4.2 Virtual Circuit and Datagram Networks

The network-layer connection service and connectionless service are similar to those in transport-layer. (with handshake or without)
**Datagram network** provides network-layer connection-less service, **VC network** provides network-layer connection service.

### 4.2.1 Virtual-Circuit Networks (no need for course)

A VC is consisted of:

1. a path between the source and destination hosts,
2. VC numbers, one number for each link along the path,
3. entries in the forwarding table in each router along the path.

### 4.2.2 Datagram Networks

In a **datagram network**, each time an end system wants to send a packet, it stamps the packet with the address of the destination end system and then pops the packet into the network.
There is **no** call setup at network layer. Routers have **no** state about end-to-end connections.
Routers forward datagram with their destination address, which is a 32 bits 01 string. Routers have forwarding tables that uses **prefix match** to determine which interface should the datagram go to.
When there are multiple matches, the router uses the **longest prefix matching rule**.

### 4.2.3 Origins of VC and Datagram Networks

VC has its roots in the telephony world. VC is more complex than datagram networks. But the Internet as a datagram network, on the other hand, grew out of the need to connect the computers together. **Sophisticated** higher level layer with **simple** network-layer.

## 4.3 What is Inside a Router?

There are two key router functions:

1. run routing algorithms/protocol (RIP, OSPF, BGP)
2. _forwarding_ datagrams from incoming to outgoing links

Four components:

- _Input ports._ Common packets are forwarded to the appropriate output port. Control packets are forwarded to the routing processor.
- _Switching fabric._ Connects the router's input ports to its output ports.
- _Output ports._ When a link is bidirectional, an output port to the link will be paired with the input port for that link on the same line card.
- _Routing processor._ Executes routing protocols and maintains routing information and forwarding tables.

### 4.3.1 Input Ports

Although the forwarding table is computed by the routing processor, a shadow copy of the forwarding table is typically stored at each input port locally and updated, as needed, by the routing processor.
To reduce the time needed to look up the forward table, many presenting structure of forwarding table had been developed, the most powerful one is **Content addressable memories(CAM)**, which returns the content of the forwarding table entry for that address in essentially constant time. Another method is to keep recently accessed entries in a cache.

### 4.3.2 Switching Fabric

Switching can be down in a number of ways:

- _Via memory._ Switching done with control of the CPU(routing processor). Note that if the memory bandwidth is such that B packets per second can be written into, or read from, memory, then the overall forwarding throughput(the total rate at which packets are transferred from input ports to output ports) must be less than B/2.
- _Via a bus._ The bus transfer only one packet at a time. The switching bandwidth is limited to the bus speed.
- _Via an interconnection network._ Can overcome the bandwidth limitation of a single bus. It is a network consists of $2n$ buses for $n$ input ports and output ports.

### 4.3.3 Output Ports

Store the packets and transmit them over the outgoing link.

### 4.3.4 Queuing

When the queues grow large, the router's buffer space will use up and cause **packet loss**.
Define **switching fabric speed** as the rate at which the switching fabric can move the packets from input ports to output ports. If switching fabric speed is at least $n$ times as fast as the input line speed then no queuing can occur at input ports. But what will happen in output ports?
The packets from different input ports may go to the same output port, so if all input ports forward 1 packet to 1 output port then there would be $n$ packets at that port. However the port could only send away 1 packet at a time. So the memory of the output port is used up and then it would drop the packet.

## 4.4 The Internet Protocol(IP): Forwarding and Addressing in the Internet

### 4.4.1 Datagram Format

Key fields:

- _Version number._ 4 bits specify the IP protocol version.
- _Header length._ An IPv4 datagram can contain a variable number of options, these 4 bits are needed to determine where in the IP datagram the data actually begins.
- _Type of service._ Used to distinguish different kinds of datagrams. For example, real-time datagrams and non-real-time ones.
- _Datagram length._ Total length of the IP datagram.
- _Identifier, flags, fragmentation offset._ Information about IP fragmentation.

**IP Data Fragmentation**

- _ID._ Which datagram does this fragment belongs to.
- _Offset._ Meaning the data should be inserted beginning at byte _offset_.
- _Flag._ If 1 means there is more, if 0 means this is the last fragment.

**题**: 假设原 IP 分组总长为 $L$, 待转发链路的 MTU 为 $M$. 当 $L>M$ 时需要分片. 每个分片的 ID 都与原分组相同, 分片封装数据大小应为 **8 的倍数**, 在计算时注意去掉 header 的 20 个字节, 分片和原分组都要去掉.

### 4.4.2 IPv4 Addressing

Let's first think about a question, how hosts are connected into the network? A host typically has a single link into the network.
The boundary between the host and the physical link is call an **interface**.
IP requires each host and router interface to have its own IP address.
Each IP address is 32 bits long. These addresses are typically written in so-called **dotted-decimal notation**. For example, 192.0.0.1.

#### Subnet

The interconnecting router interface and host interfaces forms a subnet. IP addressing assigns an address to this subnet, be like: 233.1.1.0/24, where the /24 notation is known as a **subnet mask**, indicates that the left most 24 bits define the IP address.

#### How does a host get IP address?

- Hard-coded by system admin in a file.
- **DHCP**: dynamically get address from a server when the host join the network .

#### NAT: Network Address Translation

All datagrams leaving local network have same single source NAT IP address(**outgoing** address), different source port numbers.
Datagrams with source or destination in this network have the same single source NAT IP address(**incoming** address) for source, destination.
Maintain the relationship in a **NAT translation table**.

**Motivation**: local network uses just one IP address when going outside

- uses fewer addresses of the ISP
- can change local hosts addresses without notifying outside world
- can change ISP without changing the IP address of local hosts

**Implementation**: use different ports in the router to represent different local hosts, remember the mapping relationship in the NAT table. When income and outgo datagrams, replace corresponding source IP, port and destination IP, port.

However NAT also has some problems. What if outside host want to connect local host with its original IP address? We can use relaying (Skype uses this), by connecting local host to a relay outside the local network and then connect the relay to the client.

## 4.5 Routing Algorithm

### Dijkstra's Algorithm (used by Link-state)

### Distance Vector Algorithm

The DV algorithm is iterative, asynchronous and distributed. Each DV node gets information from its neighbors. It uses **Bellman-Ford equation**
$$d_x(y)=\min_v\{c(x,v)+d_v(y)\}$$

### Hierarchical Routing

Our study of routing so far is idealized, the graph is flat, all routers are identical, which are not true in practice.
We aggregate routers into regions, **"autonomous systems" (AS)**. Routers in same AS run same routing protocol. **Gateway routers** direct link to router in another AS.
Forwarding table configured by both **intra-AS** and **inter-AS** routing algorithm.
With inter-AS, AS know how to go to other AS, and with intra-AS, that knowledge can be propagated to all the routers inside AS. When choosing path among multiple AS, routers use **hot potato routing**, which means send packet towards closest of multiple routers.

## 4.6 Routing in the Internet

**Intra-AS Routing** also known as **Interior Gateway Protocols (IGP)**. We are going to introduce some most common IGP.

### RIP (Routing Information Protocol)

Uses **distance vector** algorithm, uses **count of hops** as distance metric, with maximum of 15 hops.
RIP exchanges distance vectors information among neighbors every 30 seconds, this process is also called **advertisement**. Each advertisement consists of a list of up to 25 destination subnets among the AS.

### OSPF (Open Shortest Path First)

Uses **Link State** algorithm. OSPF advertisement carries one entry per neighbor router, they are disseminated to **entire** AS (via flooding and without hop count restriction like RIP).
To make OSPF work better, people made **hierarchical OSPF**.
It has **2-level hierarchy**: backbone and local area. Link State advertisements only in local area.
So routers can be classified into 4 classes:

1. boundary router: which is at the boundary of the AS, can connect to other AS.
2. backbone router: routers that located in backbone hierarchy.
3. area border router: routers that located at the border between backbone and local areas.
4. internal router: routers located in local areas, they have no direct link with routers in other area.

### BGP (Border Gateway Protocol)

BGP provides each AS a means to:

1. Obtain subnet reachable information from neighbor AS.
2. Propagate that information to all AS internal routers.
3. Determine "good" routers to subnets based on reachable information and policy.
   BGP allows subnet to advertise its existence to the rest of Internet.
   Between pairs of routers in BGP, they exchange routing info over semi-permanent TCP connections called: **BGP sessions**. The BGP sessions between internal routers are call iBGP sessions, while between routers from different AS are called eBGP sessions.
   In BGP destinations are not hosts but instead are **prefixes** that represents a subnet or a collection of subnets. It works pretty like subnet mask.

## 4.7 Broadcast and Multicast Routing

### Broadcast

Broadcast means we want to deliver packets from source to all the other nodes. We have 2 ways to do this: 1. source duplication and 2. in-network duplication. The first one is inefficient, imagine there are 100 other node in the network, then the source need to duplicate 100 times all by itself, that burden is heavy, we use in-network duplication to distribute the pressure.
Implement in-network duplication by generating a **spanning tree**.

### Multicast Routing

Multicast 组播, what if we only want to send packet to a subset of network nodes? We can still use broadcast but that would bother some unrelated nodes, so we need multicast.
We faced with two problems:

1. How to identify the receivers?
   Find a tree connecting them all.
2. How to address a packet sent to these receivers?
   A multicast packet is addressed using **address indirection**. That is a single identifier used for the group of receivers, and the packet with identifier will be delivered to all nodes with that identifier.

There are 2 approaches to find the tree:

1. **source-based** tree: one tree per source
   - shortest path tree (Dijkstra)
   - reverse path forwarding
2. **group-shared** tree
   - minimal spanning (Steiner Tree) not used in practice due to high complexity
   - center-based trees
     The first multicast routing protocol used in the Internet was the **DVMRP**. It implements source-based tree with reverse path forwarding and pruning.
     Now the most widely used is the **PIM** routing protocol, which explicitly recognizes 2 multicast distribution scenarios.
     In **dense** mode, it uses flood-and-prune reverse path forwarding.
     In **sparse** mode, uses rendezvous points to set up the tree.

# Chapter 5 Link Layer and LAN(local area networks)

## Introduction

Some terminology:

- hosts and routers are called **nodes**
- communication channels that connect adjacent nodes are called **links**
  - wired links
  - wireless links
  - LANs
- layer-2 packet is a **frame**, encapsulates datagram
  Link layer takes the responsibility for transferring datagram from one **node** to adjacent **node**.
  Frame uses **MAC** addresses to identify source and destination.
  Link layer also has **reliable data transfer** it works similar to the previous introduced one, and it is seldom used on low bit-error link.
  Here are some more **services**:
- flow control
- error detection
- error correction
- half-duplex and full-duplex: with half-duplex nodes at both ends of link can transmit, but not at the same time.

## Error detection and correction

### Parity Checking

Sum all the data bits together then we get the **parity bit**. If we sum over the rows and columns of data, we have **two dimensional bit parity**, and it can not only detect 1 bit error but also correct it by locating the error row and error column.

## Multiple access protocols

Shared wire is used to connect different nodes, so nodes may use the single channel at the same time and that would cause **collision**. To handle this, multiple access protocols are essential, they are distributed algorithms that determine how nodes share channel, and the communication about channel sharing must use the channel itself.

Three broad classes:

- **Channel partitioning**: (sounds like circuit switch)
  - divide channel into small pieces
  - allocate piece to node for exclusive use
- **Random Access**:
  - channel not divided, allow collision
  - "recover" from collisions
- **"Taking turns"**:
  - nodes taking turns, but nodes have more data to transfer can take longer turns
    Now lets talk about the three methods in detail.

### Channel Partitioning

Just pass, almost the same as circuit switch.

### Random Access

#### Slotted ALOHA

**Assumptions**:

- all frame same size
- time divided into equal size slots (time to transmit 1 frame)
- nodes only start transmit at slot beginning
- nodes are synchronized
- if 2 or more nodes transmit at the same slot then collision
  **Operation**:
- if transmit successfully then keep going
- if fail (meet collision) then try to re-transmit in next slot with **probability** $p$ until success

Slotted ALOHA is simple but has very poor performance with only 37% efficiency at best.

#### Pure ALOHA

Even worse performance, skip.

#### CSMA (Carrier Sense Multiple Access)

Before a node transmit frame, it **listen**, if idle then transmit the whole frame, if busy then defer transmission. There can still be collisions because there are propagation delay so nodes may not hear each other's transmission.
A better way is called **CSMA/CD**. CD refers to Collision Detection. It means when nodes hear other's transmission during its transmission, it will abort and delay the propagation with random exponential time. In this way we can reduce the time waste caused by collision(we wasted the whole transmission time before).

#### "Taking turns"

Skipped.

## Link layer addressing

### MAC address and ARP

**MAC (or LAN or physical or Ethernet) Address**:

- _function_: get frame from one interface to another physically-connected interface (same network)
- 48 bit
  **ARP (Address Resolution Protocol)**:
  We only carry IP address in datagram, how to determine MAC address with IP address? ARP do this for us.
- Each IP node (router, host) on LAN has _ARP table_
- _ARP table_: IP/MAC address mappings for some LAN nodes
  `<IP address; MAC address; TTL>` mapping will be forgotten. Node _broadcast_ its need of target MAC, then the target would response with its MAC address, and the node will store that mapping in its ARP table.

What we have talked about was happened in the same LAN, when routing to another LAN, there must be a router connecting the 2 LANs. That router would have 2 ARP tables for each LAN.

## Ethernet

Ethernet frame has a _preamble_ field, which is used to synchronize receiver, sender clock rates.
_CRC_ as error detection method. _Unreliable_, _connectionless_, _CSMA/CD_.
Ethernet's CSMA/CD takes _exponential back-off_ after aborting. Which means, the delay time equals $K*512$ bit transmission time, and $K$ is chosen from $\{0,1,2,\ldots,2^m-1\}$ where $m$ is the times that collision has happened.

## A day in the life of a web request

Really a good way to test whether you grasp the knowledge well.

# Chapter 6 Wireless and Mobile Networks

## Introduction

Elements of a wireless network:

- Wireless hosts
- Base station
  - Typically connected to wired network
  - Relay: responsible for sending packets between wired network and wireless hosts in its area.
- Wireless link
  Two modes of connection:

1. _infrastructure mode_:
   - **Base station** connects mobiles into wired network
   - handoff: mobile changes base station providing connection into wired network
2. _ad hoc mode_:
   - No base stations
   - Nodes can only transmit to other nodes within link coverage
   - Nodes organize themselves into a network: routing among themselves

## Wireless link characteristics

Wireless link are harder to handle collisions, because the signal strength would decrease as it propagates further, so the two conflict hosts may not receive each other's signal, but their same destination is confused. So we need new method called **CDMA**.

### CDMA Code Division Multiple Access

Each node has it's own chipping sequence which is a piece of code, can be used to _encode_ sender's original signal data. The code is sent before data, so the receiver can get it. The CDMA also assume data from different senders are _orthogonal_. The receiver sum the encoded signal and then _decode_(inner product) them with the code sent. If result is positive then original data is 1, else 0.

## IEEE 802.11 wireless LANs ("WiFi")

Host must _associate_ with an AP. Host would scan for AP.
**Passive Scanning**:

1. AP send _beacon_ frames
2. Host receives _beacon_ frames and send _association_ Request frame to selected AP
3. AP send _association_ Response to the host

**Active Scanning**:

1. Host broadcast _probe_ Request frame
2. AP send _probe_ Response to host
3. Host send _association_ Request to AP
4. AP send _association_ Response

**CSMA/CA(collision avoidance)**
_idea_: allow sender to "reserve" channel rather than random access of data frames: avoid collisions of long data frames.

- Sender first transmits small request-to-send _RTS_ packets to BS using CSMA. RTS may still have collisions, but they are short so the cost is low.
- BS broadcasts clear-to-send _CTS_ in response to RTS
- CTS heard by all nodes, so sender transmits data frame and other nodes will defer.
  Avoid data frame collisions completely using small reservation packets!

## Cellular Internet Access

### Components of cellular internet network architecture

cell, MSC (mobile switching center), wired network.

## Addressing and Routing to mobile users

**Basic setting**:
We have a mobile host and its original network and a foreign network and a correspondent.
_Home network_: permanent "home" of the mobile
_Permanent address_: the address of mobile in home network
_Home agent_: entity that will perform mobility functions on behalf of mobile when mobile is remote
_Visited network_: network in which mobile currently resides, its permanent address remains constant. When mobile go to the visited network, it will contact the foreign agent and the foreign agent will contact home agent, so that home agent knows where mobile is.
_Care-of-address_: address of mobile in visited network
_Foreign agent_: entity in visited network that will perform mobility functions on behalf of mobile
_Correspondent_: wants to communicate with mobile
**We could only let the end-systems handle the routing**, route table cannot handle that much change when dealing with millions of end-systems.

- _Indirect Routing_: mobile tell Foreign Agent to tell Home Agent I'm here, then when correspondent send request to Home Agent, Home Agent tell Foreign Agent then tell mobile and mobile response to correspondent. Connection setup.
- _Direct Routing_: mobile also tell Foreign Agent to tell Home Agent I am here, Home Agent _remember_ that, when correspondent request Home Agent, it tell the Foreign Agent, then correspondent request Foreign Agent then find mobile.
  If mobile keeps moving to new Foreign Agent then it's just add one more recursive step to tell the previous Foreign Agent (only tell the first one, call it Anchor Agent) I am here then tell Home Agent.

### Handle mobility in Cellular networks

Pretty similar to the content above, use MSC instead of Agents.
